# 负载均衡方案对比

LVS 的特点是：

    1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的;
    　　2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率;
    　　3、工作稳定，自身有完整的双机热备方案，如LVS+Keepalived和LVS+Heartbeat，不过我们在项目实施中用得最多的还是LVS/DR+Keepalived;
    　　4、无流量，保证了均衡器IO的性能不会收到大流量的影响;
    　　5、应用范围比较广，可以对所有应用做负载均衡;
    　　6、软件本身不支持正则处理，不能做动静分离，这个就比较遗憾了;其实现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。
    　　7、如果是网站应用比较庞大的话，实施LVS/DR+Keepalived起来就比较复杂了，特别后面有Windows Server应用的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。

Nginx 的特点是：

    　1、工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构，它的正则规则比HAProxy更为强大和灵活，这也是许多朋友喜欢它的原因之一;
    　　2、Nginx对网络的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势所在;
    　　3、Nginx安装和配置比较简单，测试起来比较方便;
    　　4、也可以承担高的负载压力且稳定，一般能支撑超过几万次的并发量;
    　　5、Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测;
    　　6、Nginx仅能支持http和Email，这样就在适用范围上面小很多，这个它的弱势;
    　　7、Nginx不仅仅是一款优秀的负载均衡器/反向代理软件，它同时也是功能强大的Web应用服务器。LNMP现在也是非常流行的web架构，大有和以前最流行的LAMP架构分庭抗争之势，在高流量的环境中也有很好的效果。
    　　8、Nginx现在作为Web反向加速缓存越来越成熟了，很多朋友都已在生产环境下投入生产了，而且反映效果不错，速度比传统的Squid服务器更快，有兴趣的朋友可以考虑用其作为反向代理加速器。

HAProxy 的特点是：

    1、HAProxy是支持虚拟主机的，以前有朋友说这个不支持虚拟主机，我这里特此更正一下。
    　　2、能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作
    　　3、支持url检测后端的服务器出问题的检测会有很好的帮助。
    　　4、它跟LVS一样，本身仅仅就只是一款负载均衡软件;单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度，在并发处理上也是优于Nginx的。
    　　5、HAProxy可以对Mysql读进行负载均衡，对后端的MySQL节点进行检测和负载均衡，不过在后端的MySQL slaves数量超过10台时性能不如LVS，所以我向大家推荐LVS+Keepalived。
    　　6、HAProxy的算法现在也越来越多了，具体有如下8种：
    　　①roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的;
    　　②static-rr，表示根据权重，建议关注;
    　　③leastconn，表示最少连接者先处理，建议关注;
    　　④ource，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注;
    　　⑤ri，表示根据请求的URI;
    　　⑥rl_param，表示根据请求的URl参数'balance url_param' requires an URL parameter name;
    　　⑦hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求;
    　　⑧rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求。

接入层从传统模式到云平台迁移面临的问题
业务概述

为了解决应用实例的可扩展、可用性、安全性问题，在不同的应用实例间分配传入的流量，需要依赖于一些负载均衡解决方案。

比如公有云 AWS ELB 提供了两种类型的负载均衡器：

Classic 负载均衡器，可基于应用程序或网络级信息路由流量，适用于在多个 EC2 实例之间进行简单的流量负载均衡

应用程序负载均衡器，可基于包括请求内容的高级应用程序级信息路由流量，适用于需要高级路由功能、微服务和基于容器的架构的应用程序。应用程序负载均衡器可将流量路由至多个服务，也可在同一 EC2 实例的多个端口之间进行负载均衡

而我们线上主要有三类型的负载均衡解决方案：

LVS，基本上当前线上所有应用的入口，最前面都会架一层 LVS，解决后端七层负载均衡器的扩展的问题

HAProxy，当前我们有小部分业务使用到了 HAProxy 来解决，更早期因为 Nginx 的 TCP Load Balancer 不支持(当前已经支持)，所以 HAProxy 在四层负载均衡层面有功能优势，并且 HAProxy 在性能情况表现也不错。不过随着 Nginx 对于 TCP Load Balancer 的支持和稳定后，HAProxy 是否有一些其他适用的场景，到时再结合着做考究

Nginx，当前是我们主要在使用的七层负载均衡的解决方案，目前在 Proxy 层我们主要是使用 Tengine 的开源解决方案，然后同时我们也围绕着 Nginx，基于 LUA 也有做了一些相关的扩展，比如流控等相关功能。

在业务往容器化方向去做管理的时候，也会有负载均衡相关问题需要解决，不过在容器化过程，除了面临之前以物理机提供业务服务的时候所面临的一些负载均衡问题外，还需要会有一些差异化的地方：

容器化后，应用节点随时可能会被调度，从而应用节点的 IP 本身会是一个不断变化的过程，所以需要去解决业务容器的服务发现的问题

集群内部容器的 IP 管理是使用内部虚拟网络，而虚拟网络的 IP 是外部节点路由无法到达，所以需要解决容器集群内和集群外的服务互通的问题

有两个典型的线上业务场景在容器化后需要去解决：

HTTP 接口调用问题

RPC 接口调用问题

RPC 当前我们的方案 Tardis（架构和电商），是直接走 gRPC 直连的方式，在 client 做一些负载均衡策略和高可用策略，而 service 通过注册自己的 IP 到 etcd 来供 client 发现服务，这种方式在容器化后，在与容器化外部集群交互的时候，会遇到 IP 的路由问题需要去解决。PHP 的 RPC 方案是做 YAR 的方式，也是以 HTTP 做协议的交互，所以和 HTTP 面临的问题是类似。而广告平台，是以百度 sofa 作为 RPC 方案，也是节点 IP 直连的方式，和 Tardis 面临的问题一样

备注：接下来下面的所有讨论，都是建立在我们的网络方案不是基于 HostNetwork 的方案来进行，因为如果基于 HostNetwork 的方案的话，那么 Edge Router 的路由不可达的问题就不存在，从而方案还有存在其他的选择的考虑
